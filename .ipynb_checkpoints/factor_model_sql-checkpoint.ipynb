{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/python3\n",
    "# TODO: change symbol varchar to char\n",
    "\n",
    "# mysql  Ver 14.14 Distrib 5.7.18, for Linux (x86_64) using  EditLine wrapper\n",
    "# data files are ./fff.csv and ./data\n",
    "'''\n",
    "notes:\n",
    "1. get & clean data\n",
    "    tech:\n",
    "        small: NASDAQ:NTGR, NYSE:PLT\n",
    "        medium: NYSE:SMI\n",
    "        large: NASDAQ:AAPL, NASDAQ:AMZN\n",
    "    non-tech:\n",
    "        small: NYSE:HRI, NYSE:DF\n",
    "        medium: NASDAQ:UHAL\n",
    "        larege: NYSE: BRK.A, NYSE:XOM\n",
    "2. OLS with 3 classic factor\n",
    "3. get google search trend\n",
    "4. regress on different sectors of revenue\n",
    "5. automate the process\n",
    "\n",
    "x. NEXT: ML training\n",
    "'''\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as plt\n",
    "from statsmodels.formula.api import ols\n",
    "# http://www.statsmodels.org/devel/generated/statsmodels.regression.linear_model.RegressionResults.html\n",
    "import MySQLdb\n",
    "# DROP TABLE symbols, AAPL,AMZN,BRK_A,DF,HRI,NTGR,PLT,SMI,UHAL,XOM,fff;\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_stock_to_db(symbol, csv_file_path):\n",
    "    # add table of stock prices from csv file\n",
    "    sql_1 = \"CREATE TABLE \" + symbol + \" (date TEXT NOT NULL, close DECIMAL(18,4) NOT NULL)\"\n",
    "    cur.execute(sql_1)\n",
    "    sql_2 = \"LOAD data local infile \" + csv_file_path + \" INTO TABLE \" + symbol + r\"\"\" FIELDS TERMINATED BY ',' ENCLOSED BY '\"' LINES TERMINATED BY '\\n'  IGNORE 1 LINES (date, close)\"\"\"\n",
    "    cur.execute(sql_2)\n",
    "#     sql_3 = \"UPDATE \" + symbol + \" SET date = (SELECT UNIX_TIMESTAMP(DATE(STR_TO_DATE(date, '%m/%d/%Y %H:%i')));\"\n",
    "    sql_3 = \"UPDATE \" + symbol + \" SET date = DATE((SELECT STR_TO_DATE(date, '%m/%d/%Y %H:%i')));\"\n",
    "    cur.execute(sql_3)\n",
    "\n",
    "\n",
    "def add_factors_to_db(symbol, csv_file_path):\n",
    "    # add table of factors data\n",
    "    sql_1 = \"CREATE TABLE \" + symbol + \" (date TEXT NOT NULL, PREM DECIMAL(18,4) NOT NULL, SMB DECIMAL(18,4) NOT NULL, HML DECIMAL(18,4) NOT NULL, RF DECIMAL(18,4) NOT NULL)\"\n",
    "    cur.execute(sql_1)\n",
    "    sql_2 = \"LOAD data local infile \" + csv_file_path + \" INTO TABLE \" + symbol + r\"\"\" FIELDS TERMINATED BY ',' ENCLOSED BY '\"' LINES TERMINATED BY '\\n'  IGNORE 1 LINES (date, PREM, SMB, HML,RF)\"\"\"\n",
    "    cur.execute(sql_2)\n",
    "    sql_3 = \"UPDATE \" + symbol + \" SET date = DATE((SELECT STR_TO_DATE(date, '%Y%m%d')));\"\n",
    "    cur.execute(sql_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "db = MySQLdb.connect(host=\"localhost\",\n",
    "                    user=\"steve\",\n",
    "                    passwd=\"mima\",\n",
    "                    db=\"factors\")\n",
    "\n",
    "cur = db.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# stock data; 20120706-20170630\n",
    "\n",
    "# TODO: automate the dictionary generation, import sys, recognize file name\n",
    "# csv_file_list = os.listdir('data/')\n",
    "# stock_list = []\n",
    "# stock_file_dict = {}\n",
    "# for _ in csv_file_list:\n",
    "#     stock_list.append(_.split('.')[0])\n",
    "#     stock_file_dict[_.split('.')[0]] = \"data/\" + _\n",
    "    \n",
    "# print(stock_list)\n",
    "# print(stock_file_dict)\n",
    "\n",
    "# create table of symbols\n",
    "stock_list = [r\"'AAPL'\", r\"'AMZN'\", r\"'BRK_A'\", r\"'DF'\", r\"'HRI'\", r\"'NTGR'\", r\"'PLT'\", r\"'SMI'\", r\"'UHAL'\", r\"'XOM'\"]\n",
    "cur.execute(\"CREATE TABLE symbols (id INT NOT NULL AUTO_INCREMENT PRIMARY KEY, symbol VARCHAR(6) UNIQUE NOT NULL)\")\n",
    "\n",
    "for _ in stock_list:\n",
    "    sql = \"INSERT INTO symbols (symbol) VALUES (\" + _ + \")\"\n",
    "    cur.execute(sql)\n",
    "    \n",
    "\n",
    "stock_file_dict = {\"AAPL\" : r\"'data/AAPL.csv'\",\n",
    "                  \"AMZN\" : r\"'data/AMZN.csv'\",\n",
    "                  \"BRK_A\" : r\"'data/BRK_A.csv'\",\n",
    "                  \"DF\" : r\"'data/DF.csv'\",\n",
    "                  \"HRI\" : r\"'data/HRI.csv'\",\n",
    "                  \"NTGR\" : r\"'data/NTGR.csv'\",\n",
    "                  \"PLT\" : r\"'data/PLT.csv'\",\n",
    "                  \"SMI\" : r\"'data/SMI.csv'\",\n",
    "                  \"UHAL\" : r\"'data/UHAL.csv'\",\n",
    "                  \"XOM\" : r\"'data/XOM.csv'\"}\n",
    "\n",
    "for _ in stock_file_dict.keys():\n",
    "    symbol = _\n",
    "    csv_file_path = stock_file_dict[_]\n",
    "    add_stock_to_db(symbol, csv_file_path)\n",
    "\n",
    "# add factors data to DB\n",
    "add_factors_to_db('fff', r\"'fff.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import stock data from DB\n",
    "df = pd.DataFrame(index=pd.read_sql(\"SELECT date FROM AAPL\", con=db).date)\n",
    "\n",
    "for _ in stock_file_dict.keys():\n",
    "    df[_] = pd.read_sql(\"SELECT close FROM \" + _, con=db).values\n",
    "\n",
    "# data preprocessing\n",
    "df = df.pct_change()[1:]*100\n",
    "df = df[:255]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import factors data from DB\n",
    "ndf = pd.DataFrame()\n",
    "ndf[[\"PREM\",\"SMB\",\"HML\",\"RF\"]]=pd.read_sql(\"SELECT * FROM fff\", con=db)[1:][[\"PREM\",\"SMB\",\"HML\",\"RF\"]]\n",
    "for _ in ndf.columns:\n",
    "    df[_] = ndf[_].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_dict = {}\n",
    "pvalues_dict = {}\n",
    "for i in range(len(stock_list)):\n",
    "    key = df.columns[i]\n",
    "    model_dict[key] = ols(df.columns[i] + \" ~ PREM+SMB+HML\", df).fit()\n",
    "    print(key, model_dict[key].pvalues[model_dict[key].pvalues < 0.05])\n",
    "    print(key, model_dict[key].params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "db.commit()\n",
    "db.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
